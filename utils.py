import json
import random
import numpy as np
import faiss
import sys, os

sys.path.append(os.path.dirname(os.path.abspath(__file__)) + "/..")

from config import (
    SYSTEM_PROMPT_PATH,
    GOOD_DIALOGS_PATH,
    GOOD_INDEX_PATH,
    BAD_DIALOGS_PATH,
    BAD_INDEX_PATH,
    FEEDBACK_LESSONS_PATH,
    DIALOG_CHUNKS_PATH,
    REAL_INDEX_PATH,
    REAL_DIALOGS_TXT_PATH
)
from dialog_memory import get_history
from openai import OpenAI
from log import log
from scripts.convert_real_dialogs import load_real_dialogs_from_txt

client = OpenAI()

# --- üß† –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç—É ---
with open(SYSTEM_PROMPT_PATH, "r", encoding="utf-8") as f:
    SYSTEM_PROMPT = f.read().strip()

# --- ‚úÖ GOOD –ø—Ä–∏–∫–ª–∞–¥–∏ ---
try:
    with open(GOOD_DIALOGS_PATH, "r", encoding="utf-8") as f:
        good_chunks = [json.loads(line) for line in f if line.strip()]
    good_index = faiss.read_index(GOOD_INDEX_PATH)
    good_texts = [chunk["text"] for chunk in good_chunks if "text" in chunk]
except Exception as e:
    print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ good_dialogs: {e}")
    good_index = None
    good_texts = []

# --- ‚ùå BAD –ø—Ä–∏–∫–ª–∞–¥–∏ ---
try:
    with open(BAD_DIALOGS_PATH, "r", encoding="utf-8") as f:
        bad_chunks = [json.loads(line) for line in f if line.strip()]
    bad_index = faiss.read_index(BAD_INDEX_PATH)
    bad_texts = [chunk["text"] for chunk in bad_chunks if "text" in chunk]
except Exception as e:
    print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ bad_dialogs: {e}")
    bad_index = None
    bad_texts = []

# --- üìò –£—Ä–æ–∫–∏ –∑ —Ñ—ñ–¥–±–µ–∫—É ---
try:
    with open(FEEDBACK_LESSONS_PATH, "r", encoding="utf-8") as f:
        feedback_lessons = json.load(f)
except Exception:
    feedback_lessons = []

# --- üéØ –†–µ–∞–ª—å–Ω—ñ –¥—ñ–∞–ª–æ–≥–∏ (–∑ txt –Ω–∞–ø—Ä—è–º—É) ---
try:
    raw_texts = load_real_dialogs_from_txt(REAL_DIALOGS_TXT_PATH)

    # üîç –û—á–∏—â–µ–Ω–Ω—è: –∑–∞–ª–∏—à–∞—î–º–æ –ª–∏—à–µ –Ω–µ–ø–æ—Ä–æ–∂–Ω—ñ —Ä—è–¥–∫–∏
    real_texts = [t.strip() for t in raw_texts if isinstance(t, str) and t.strip()]

    if not real_texts:
        raise ValueError("–°–ø–∏—Å–æ–∫ real_texts –ø–æ—Ä–æ–∂–Ω—ñ–π –ø—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è.")

    if not os.path.exists(REAL_INDEX_PATH):
        print("‚ö†Ô∏è –Ü–Ω–¥–µ–∫—Å —Ä–µ–∞–ª—å–Ω–∏—Ö –¥—ñ–∞–ª–æ–≥—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π...")

        # üß† –ì–µ–Ω–µ—Ä—É—î–º–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏ (OpenAI –æ–±–º–µ–∂—É—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–∏–º–≤–æ–ª—ñ–≤)
        embeddings = client.embeddings.create(
            model="text-embedding-3-small",
            input=real_texts
        )
        vectors = np.array([e.embedding for e in embeddings.data], dtype=np.float32)
        real_index = faiss.IndexFlatL2(len(vectors[0]))
        real_index.add(vectors)
        faiss.write_index(real_index, REAL_INDEX_PATH)
    else:
        real_index = faiss.read_index(REAL_INDEX_PATH)

except Exception as e:
    print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ real_dialogs: {e}")
    real_texts = []
    real_index = None


# --- üõ† –õ–æ–≥ ---
def log(message):
    print(message)

# --- üß© –ü–æ–¥—ñ–ª –¥—ñ–∞–ª–æ–≥—É –Ω–∞ —á–∞–Ω–∫–∏ ---
def split_dialog_into_chunks(dialog_text: str, label: str = "") -> list:
    lines = dialog_text.strip().split("\n")
    chunks = []
    buffer = []
    for line in lines:
        if line.strip():
            buffer.append(line)
        if len(buffer) >= 4:
            chunks.append({"text": "\n".join(buffer), "label": label})
            buffer = []
    if buffer:
        chunks.append({"text": "\n".join(buffer), "label": label})
    return chunks

# --- üîç –ü–æ—à—É–∫ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ ---
def search_good_examples(query, top_k=3):
    if not good_index or not good_texts:
        return []
    if not isinstance(query, str) or not query.strip():
        return []
    try:
        emb = client.embeddings.create(model="text-embedding-3-small", input=[query.strip()]).data[0].embedding
        emb_np = np.array([emb], dtype=np.float32)
        distances, indices = good_index.search(emb_np, top_k)
        return [good_texts[i] for i in indices[0] if i < len(good_texts)]
    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É good_examples: {e}")
        return []

def search_bad_examples(query, top_k=2):
    if not bad_index or not bad_texts:
        return []
    if not isinstance(query, str) or not query.strip():
        return []
    try:
        emb = client.embeddings.create(model="text-embedding-3-small", input=[query.strip()]).data[0].embedding
        emb_np = np.array([emb], dtype=np.float32)
        distances, indices = bad_index.search(emb_np, top_k)
        return [bad_texts[i] for i in indices[0] if i < len(bad_texts)]
    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É bad_examples: {e}")
        return []

def search_real_examples(query, top_k=2):
    if not real_index or not real_texts:
        return []
    if not isinstance(query, str) or not query.strip():
        return []
    try:
        emb = client.embeddings.create(model="text-embedding-3-small", input=[query.strip()]).data[0].embedding
        emb_np = np.array([emb], dtype=np.float32)
        distances, indices = real_index.search(emb_np, top_k)
        return [real_texts[i] for i in indices[0] if i < len(real_texts)]
    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É real_examples: {e}")
        return []

# --- üß± –ü–æ–±—É–¥–æ–≤–∞ prompt –¥–ª—è OpenAI ---
def build_messages(chat_id, user_input, context_chunks, memory):
    history = get_history(memory, chat_id)
    meta = memory.get(str(chat_id), {}).get("_meta", {})

    prompt_parts = [SYSTEM_PROMPT]
    if meta.get("suspicion"):
        prompt_parts.append("–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–≤–æ–¥–∏—Ç—å—Å—è –ø—ñ–¥–æ–∑—Ä—ñ–ª–æ, –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –æ–±–µ—Ä–µ–∂–Ω–æ.")
    if meta.get("lang") == "ru":
        prompt_parts.append("–ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—Å–∏–≤ –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —Ä–æ—Å—ñ–π—Å—å–∫–æ—é.")
    if meta.get("tone") == "formal":
        prompt_parts.append("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –±—ñ–ª—å—à –æ—Ñ—ñ—Ü—ñ–π–Ω–∏–π —Å—Ç–∏–ª—å.")
    if meta.get("tone") == "casual":
        prompt_parts.append("–ú–æ–∂–Ω–∞ —Å–ø—ñ–ª–∫—É–≤–∞—Ç–∏—Å—å —Ç—Ä–æ—Ö–∏ –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ, –ø–æ-–¥—Ä—É–∂–Ω—å–æ–º—É.")
    if meta.get("humor"):
        prompt_parts.append("–î–æ–∑–≤–æ–ª–µ–Ω–æ —Ç—Ä–æ—Ö–∏ –≥—É–º–æ—Ä—É –∞–±–æ –µ–º–æ–¥–∑—ñ.")

    messages = [{"role": "system", "content": "\n".join(prompt_parts)}]

    for pair in history[-10:]:
        messages.append({"role": "user", "content": pair["from_user"]})
        messages.append({"role": "assistant", "content": pair["from_ai"]})

    for chunk in context_chunks:
        messages.append({"role": "system", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {chunk['text']}"})

    for ex in search_good_examples(user_input):
        messages.append({"role": "system", "content": f"–ü—Ä–∏–∫–ª–∞–¥: {ex}"})

    for real_ex in search_real_examples(user_input):
        messages.append({"role": "system", "content": f"–†–µ–∞–ª—å–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: {real_ex}"})

    for bad_ex in search_bad_examples(user_input):
        messages.append({"role": "system", "content": f"–£–Ω–∏–∫–∞–π —Ç–∞–∫–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π: {bad_ex}"})

    for lesson in feedback_lessons:
        pattern = lesson.get("pattern", "").lower()
        if pattern in user_input.lower():
            messages.append({"role": "system", "content": f"–ü–æ—Ä–∞–¥–∞: {lesson['advice']}"})

    messages.append({"role": "user", "content": user_input})
    return messages

# --- ü§ñ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤—ñ–¥ OpenAI ---
def get_openai_response(messages):
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.8,
            presence_penalty=0.3,
            frequency_penalty=0.2
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ö†Ô∏è –í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞: {e}"

# --- üîß –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É ---
def format_text(text):
    return text.replace("\n\n", "\n").strip()

# --- üïµÔ∏è‚Äç‚ôÇÔ∏è –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ---
def detect_source(dialog_text: str) -> str:
    text = dialog_text.lower()
    if any(word in text for word in ["—Ç–µ–ª–µ–≥—Ä–∞–º", "—Ç–≥", "–∫–∞–Ω–∞–ª", "–æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –≤ —Ç–µ–ª–µ–≥—Ä–∞–º—ñ"]):
        return "telegram"
    elif any(word in text for word in ["olx", "–æ–ª—Ö", "–æ–≥–æ–ª–æ—à–µ–Ω–Ω—è"]):
        return "olx"
    elif any(word in text for word in ["—ñ–Ω—Å—Ç–∞–≥—Ä–∞–º", "instagram", "—Å—Ç–æ—Ä—ñ—Å", "reels"]):
        return "instagram"
    elif any(word in text for word in ["tiktok", "—Ç—ñ–∫—Ç–æ–∫", "tt", "–≤—ñ–¥–µ–æ"]):
        return "tiktok"
    elif any(word in text for word in ["–¥—Ä—É–≥", "–ø–æ—Ä–∞–¥–∏–≤", "—Ä–µ–∫–æ–º–µ–Ω–¥—É–≤–∞–≤", "–∑–Ω–∞–π–æ–º–∏–π"]):
        return "other"
    return "unknown"

# --- üì• –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç—É –¥—ñ–∞–ª–æ–≥—É ---
def parse_dialog_text(text):
    lines = text.strip().splitlines()
    parsed = []
    for line in lines:
        line = line.strip()
        if line.startswith("üë§"):
            parsed.append({"role": "user", "text": line[1:].strip()})
        elif line.startswith("ü§ñ"):
            parsed.append({"role": "bot", "text": line[1:].strip()})
    return parsed
