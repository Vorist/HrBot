import os
import json
import faiss
import numpy as np
import sys
from hashlib import sha256
from datetime import datetime

# –î–æ–¥–∞—î–º–æ –∫–æ—Ä—ñ–Ω—å –ø—Ä–æ—î–∫—Ç—É
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from config import (
    BAD_DIALOGS_PATH,
    BAD_INDEX_PATH,
    BAD_DIALOG_CHUNKS_PATH,
    EMBED_CACHE_PATH
)

from knowledge_embeddings import embed_texts
from utils import split_dialog_into_chunks, log

LOG_PATH = "logs/training_log.txt"

def log_to_file(message: str):
    os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    full_message = f"{timestamp} {message}"
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(full_message + "\n")
    print(full_message)


def load_embed_cache():
    if os.path.exists(EMBED_CACHE_PATH):
        try:
            with open(EMBED_CACHE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_embed_cache(cache):
    try:
        with open(EMBED_CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log_to_file(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –∫–µ—à –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤: {e}")


def train_on_bad_dialogs():
    log_to_file("üö´ –°—Ç–∞—Ä—Ç –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ BAD –¥—ñ–∞–ª–æ–≥–∞—Ö...")

    if not os.path.exists(BAD_DIALOGS_PATH):
        log_to_file(f"‚ùå –§–∞–π–ª {BAD_DIALOGS_PATH} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    cache = load_embed_cache()
    all_chunks = []
    hashes_seen = set()

    with open(BAD_DIALOGS_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                if "text" in obj:
                    chunks = split_dialog_into_chunks(obj["text"], label="bad")
                    for chunk in chunks:
                        h = sha256(chunk["text"].encode("utf-8")).hexdigest()
                        if h not in hashes_seen:
                            hashes_seen.add(h)
                            chunk["hash"] = h
                            all_chunks.append(chunk)
            except Exception as e:
                log_to_file(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ä—è–¥–æ–∫ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É: {e}")
                continue

    if not all_chunks:
        log_to_file("‚ö†Ô∏è –ñ–æ–¥–Ω–æ–≥–æ –≤–∞–ª—ñ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    log_to_file(f"üî¢ –û–±—Ä–æ–±–∫–∞ {len(all_chunks)} bad-—á–∞–Ω–∫—ñ–≤...")

    texts = [c["text"] for c in all_chunks]
    embeddings = []
    new_cache = dict(cache)

    for text in texts:
        h = sha256(text.encode("utf-8")).hexdigest()
        if h in cache:
            emb = cache[h]
        else:
            emb = embed_texts([text])[0].tolist()
        embeddings.append(emb)
        new_cache[h] = emb

    save_embed_cache(new_cache)

    # --- FAISS --- #
    dim = len(embeddings[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(embeddings, dtype=np.float32))
    faiss.write_index(index, BAD_INDEX_PATH)
    log_to_file(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ FAISS-—ñ–Ω–¥–µ–∫—Å –∑ {len(embeddings)} BAD-—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤ ‚Üí {BAD_INDEX_PATH}")

    # --- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤ --- #
    try:
        with open(BAD_DIALOG_CHUNKS_PATH, "w", encoding="utf-8") as f:
            json.dump(all_chunks, f, ensure_ascii=False, indent=2)
        log_to_file(f"üìÅ –ó–±–µ—Ä–µ–∂–µ–Ω–æ —á–∞–Ω–∫–∏ ‚Üí {BAD_DIALOG_CHUNKS_PATH}")
    except Exception as e:
        log_to_file(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤: {e}")


if __name__ == "__main__":
    train_on_bad_dialogs()
