# trainer/build_dialog_chunks.py

import os
import json
import sys
import hashlib

sys.path.append(os.path.dirname(os.path.abspath(__file__)) + "/..")

from config import REAL_DIALOGS_PATH, DIALOG_CHUNKS_PATH

USED_DIALOGS_PATH = "data/used_real_dialogs.json"

# --- üîê –•–µ—à—É–≤–∞–Ω–Ω—è –¥–ª—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ—Å—Ç—ñ --- #
def hash_dialog(dialog_text):
    return hashlib.md5(dialog_text.encode("utf-8")).hexdigest()

# --- üßº –û—á–∏—â–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É --- #
def format_text(text):
    return text.strip().replace("  ", " ")

# --- üì• –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –¥—ñ–∞–ª–æ–≥—É --- #
def detect_source(dialog_text):
    first = dialog_text.strip().split("\n")[0]
    if first.startswith("üì• –î–∂–µ—Ä–µ–ª–æ: "):
        return first.replace("üì• –î–∂–µ—Ä–µ–ª–æ: ", "").strip()
    return "–Ω–µ–≤—ñ–¥–æ–º–æ"

# --- üìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥—ñ–∞–ª–æ–≥—ñ–≤ --- #
def load_real_dialogs():
    if not os.path.exists(REAL_DIALOGS_PATH):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {REAL_DIALOGS_PATH}")
        return []
    with open(REAL_DIALOGS_PATH, "r", encoding="utf-8") as f:
        raw = f.read().strip()
    return [d.strip() for d in raw.split("\n\n") if d.strip()]

# --- üßæ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö —Ö–µ—à—ñ–≤ --- #
def load_used_hashes():
    if os.path.exists(USED_DIALOGS_PATH):
        try:
            with open(USED_DIALOGS_PATH, "r", encoding="utf-8") as f:
                return set(json.load(f))
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ used_real_dialogs.json: {e}")
    return set()

def save_used_hashes(hashes):
    os.makedirs(os.path.dirname(USED_DIALOGS_PATH), exist_ok=True)
    with open(USED_DIALOGS_PATH, "w", encoding="utf-8") as f:
        json.dump(list(hashes), f, ensure_ascii=False, indent=2)

# --- üß© –†–æ–∑–±–∏—Ç—Ç—è –¥—ñ–∞–ª–æ–≥—É –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏ --- #
def split_dialog_into_chunks(dialog_text):
    source = detect_source(dialog_text)
    lines = dialog_text.strip().split("\n")[1:]  # –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π —Ä—è–¥–æ–∫
    chunks = []

    for line in lines:
        clean = format_text(line)
        if clean:
            chunks.append({
                "text": clean,
                "source": source
            })
    return chunks

# --- üß† –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è --- #
def build_dialog_chunks():
    dialogs = load_real_dialogs()
    used_hashes = load_used_hashes()

    new_chunks = []
    new_hashes = set()

    for dialog in dialogs:
        h = hash_dialog(dialog)
        if h in used_hashes:
            continue
        new_chunks.extend(split_dialog_into_chunks(dialog))
        new_hashes.add(h)

    if not new_chunks:
        print("‚ö†Ô∏è –ù–æ–≤–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    os.makedirs(os.path.dirname(DIALOG_CHUNKS_PATH), exist_ok=True)
    with open(DIALOG_CHUNKS_PATH, "w", encoding="utf-8") as f:
        for chunk in new_chunks:
            f.write(json.dumps(chunk, ensure_ascii=False) + "\n")

    save_used_hashes(used_hashes.union(new_hashes))
    print(f"‚úÖ –î–æ–¥–∞–Ω–æ {len(new_chunks)} –Ω–æ–≤–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤ ‚Üí {DIALOG_CHUNKS_PATH}")

# --- ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    build_dialog_chunks()
